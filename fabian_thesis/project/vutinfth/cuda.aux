\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*{\memsetcounter}[2]{}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{acronym}{alg}{acr}{acn}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{cuda.ist}
\@glsorder{word}
\select@language{naustrian}
\@writefile{toc}{\select@language{naustrian}}
\@writefile{lof}{\select@language{naustrian}}
\@writefile{lot}{\select@language{naustrian}}
\select@language{naustrian}
\@writefile{toc}{\select@language{naustrian}}
\@writefile{lof}{\select@language{naustrian}}
\@writefile{lot}{\select@language{naustrian}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{naustrian}
\@writefile{toc}{\select@language{naustrian}}
\@writefile{lof}{\select@language{naustrian}}
\@writefile{lot}{\select@language{naustrian}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{naustrian}
\@writefile{toc}{\select@language{naustrian}}
\@writefile{lof}{\select@language{naustrian}}
\@writefile{lot}{\select@language{naustrian}}
\select@language{naustrian}
\@writefile{toc}{\select@language{naustrian}}
\@writefile{lof}{\select@language{naustrian}}
\@writefile{lot}{\select@language{naustrian}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{Kurzfassung}{ix}{chapter*.3}}
\@writefile{loa}{\addvspace {10\p@ }}
\select@language{naustrian}
\@writefile{toc}{\select@language{naustrian}}
\@writefile{lof}{\select@language{naustrian}}
\@writefile{lot}{\select@language{naustrian}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{Abstract}{xi}{chapter*.4}}
\@writefile{loa}{\addvspace {10\p@ }}
\select@language{naustrian}
\@writefile{toc}{\select@language{naustrian}}
\@writefile{lof}{\select@language{naustrian}}
\@writefile{lot}{\select@language{naustrian}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {chapter}{Contents}{xiii}{section*.5}}
\citation{Sanders:2010:CEI:1891996}
\citation{Grcar2011163}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {1}Introduction}{1}{chapter.1}}
\@writefile{loa}{\addvspace {10\p@ }}
\citation{opac-b1133063}
\citation{Sanders:2010:CEI:1891996}
\citation{Kirk:2010:PMP:1841511}
\citation{Kirk:2010:PMP:1841511}
\citation{Introduction-to-GPUs}
\citation{nvidia_kepler_2012}
\citation{wiki:gaussian}
\citation{Grcar2011163}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {2}Related Work}{3}{chapter.2}}
\@writefile{loa}{\addvspace {10\p@ }}
\citation{parmeth}
\citation{pipelinecomp}
\citation{opac-b1133063}
\citation{Kirk:2010:PMP:1841511}
\citation{wiki:CPU_block_dia}
\citation{wiki:CPU_block_dia}
\citation{tatourian}
\citation{tatourian}
\citation{Introduction-to-GPUs}
\citation{Introduction-to-GPUs}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {3}State Of The Art: The GPU Architecture}{5}{chapter.3}}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}The GPU Architecture}{5}{section.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Streaming Multiprocessors}{5}{subsection.3.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces A simple s draft of a SM Source: \cite  {Introduction-to-GPUs}\relax }}{5}{figure.caption.7}}
\newlabel{fig:SM}{{\M@TitleReference {3.2}{A simple s draft of a SM Source: \cite  {Introduction-to-GPUs}\relax }}{5}{A simple s draft of a SM Source: \cite {Introduction-to-GPUs}\relax }{figure.caption.7}{}}
\citation{Kirk:2010:PMP:1841511}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:cpu arch}{{\M@TitleReference {3.1a}{A block diagram of a simple CPU architecture Source: \cite  {wiki:CPU_block_dia}\relax }}{6}{A block diagram of a simple CPU architecture Source: \cite {wiki:CPU_block_dia}\relax }{figure.caption.6}{}}
\newlabel{sub@fig:cpu arch}{{\M@TitleReference {a}{A block diagram of a simple CPU architecture Source: \cite  {wiki:CPU_block_dia}\relax }}{6}{A block diagram of a simple CPU architecture Source: \cite {wiki:CPU_block_dia}\relax }{figure.caption.6}{}}
\newlabel{fig:gpu arch}{{\M@TitleReference {3.1b}{A block diagram of a simple GPU architecture which consists of 8 SMs(Thread Processors). Inside of each SM the parallel ALUs are located. Source: \cite  {tatourian}\relax }}{6}{A block diagram of a simple GPU architecture which consists of 8 SMs(Thread Processors). Inside of each SM the parallel ALUs are located. Source: \cite {tatourian}\relax }{figure.caption.6}{}}
\newlabel{sub@fig:gpu arch}{{\M@TitleReference {b}{A block diagram of a simple GPU architecture which consists of 8 SMs(Thread Processors). Inside of each SM the parallel ALUs are located. Source: \cite  {tatourian}\relax }}{6}{A block diagram of a simple GPU architecture which consists of 8 SMs(Thread Processors). Inside of each SM the parallel ALUs are located. Source: \cite {tatourian}\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Comparison between CPU and GPU\relax }}{6}{figure.caption.6}}
\newlabel{fig:gpu_vs._cpu}{{\M@TitleReference {3.1}{Comparison between CPU and GPU\relax }}{6}{Comparison between CPU and GPU\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Global Memory}{6}{subsection.3.1.2}}
\citation{Sanders:2010:CEI:1891996}
\citation{Kirk:2010:PMP:1841511}
\citation{Introduction-to-GPUs}
\citation{Introduction-to-GPUs}
\citation{nvidia_kepler_2012}
\citation{nvidia_kepler_2012}
\@writefile{toc}{\contentsline {subsubsection}{Constant Memory}{7}{section*.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}BUS-System}{7}{subsection.3.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}The CUDA Architecture}{7}{section.3.2}}
\citation{nvidia_kepler_2012}
\citation{nvidia_kepler_2012}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Hardware}{8}{subsection.3.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Block diagram of a SMX (Streaming Multiprocessor). Cudacores are divided into Warps which get executed by the Warp Scheduler. The cores inside of the SMX can access the Shared Memory, Read-Only Cache and the Texture Memory. Source: \cite  {nvidia_kepler_2012}\relax }}{8}{figure.caption.9}}
\newlabel{fig:smx}{{\M@TitleReference {3.3}{Block diagram of a SMX (Streaming Multiprocessor). Cudacores are divided into Warps which get executed by the Warp Scheduler. The cores inside of the SMX can access the Shared Memory, Read-Only Cache and the Texture Memory. Source: \cite  {nvidia_kepler_2012}\relax }}{8}{Block diagram of a SMX (Streaming Multiprocessor). Cudacores are divided into Warps which get executed by the Warp Scheduler. The cores inside of the SMX can access the Shared Memory, Read-Only Cache and the Texture Memory. Source: \cite {nvidia_kepler_2012}\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{SMX, SMM, ...: A "Next Gen" SM}{8}{section*.10}}
\citation{Introduction-to-GPUs}
\citation{nvidia_kepler_2012}
\citation{Kirk:2010:PMP:1841511}
\citation{nvidia_kepler_2012}
\@writefile{toc}{\contentsline {subsubsection}{CUDA Cores}{9}{section*.11}}
\@writefile{toc}{\contentsline {subsubsection}{Warps}{9}{section*.12}}
\@writefile{toc}{\contentsline {subsubsection}{Warp Scheduler}{9}{section*.13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Memory inside of the SM}{9}{subsection.3.2.2}}
\citation{nvidia_kepler_2012}
\citation{Sanders:2010:CEI:1891996}
\citation{Sanders:2010:CEI:1891996}
\citation{Kirk:2010:PMP:1841511}
\citation{toolkit}
\citation{toolkit}
\citation{Sanders:2010:CEI:1891996}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Software}{10}{subsection.3.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{Blocks}{10}{section*.15}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Brief illustration of a Kernel function which launches threads inside blocks Source: \cite  {toolkit}\relax }}{11}{figure.caption.14}}
\newlabel{fig:kernel_launch}{{\M@TitleReference {3.4}{Brief illustration of a Kernel function which launches threads inside blocks Source: \cite  {toolkit}\relax }}{11}{Brief illustration of a Kernel function which launches threads inside blocks Source: \cite {toolkit}\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{Threads}{11}{section*.16}}
\citation{Grcar2011163}
\citation{wiki:gaussian}
\citation{wiki:gaussian}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {4}Solving Linear Equations with CUDA}{13}{chapter.4}}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Gaussian Elimination In General}{13}{section.4.1}}
\citation{Sanders:2010:CEI:1891996}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Attempt To Parallelize The Problem}{14}{section.4.2}}
\newlabel{sec:parallelize_prob}{{\M@TitleReference {4.2}{Attempt To Parallelize The Problem}}{14}{Attempt To Parallelize The Problem}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Vector parallelization}{14}{subsection.4.2.1}}
\newlabel{subsec:vector_par}{{\M@TitleReference {4.2.1}{Vector parallelization}}{14}{Vector parallelization}{subsection.4.2.1}{}}
\citation{opac-b1133063}
\citation{parmeth}
\@writefile{loa}{\contentsline {algocf}{\numberline {4.1}{\ignorespaces Gauss algorithm: Forward elimination\relax }}{15}{algocf.4.1}}
\newlabel{alg:forward_elem}{{\M@TitleReference {4.1}{Attempt To Parallelize The Problem}}{15}{Attempt To Parallelize The Problem}{algocf.4.1}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4.2}{\ignorespaces Gauss algorithm: Back substitution\relax }}{15}{algocf.4.2}}
\newlabel{alg:back_subst}{{\M@TitleReference {4.2}{Attempt To Parallelize The Problem}}{15}{Attempt To Parallelize The Problem}{algocf.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Parallel Row-Cyclic implementation}{15}{subsection.4.2.2}}
\citation{Sanders:2010:CEI:1891996}
\citation{stack:overflow_2014}
\citation{stack:overflow_2014}
\citation{pipelinecomp}
\citation{opac-b1133063}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Sum-reduction in back substitution}{16}{subsection.4.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Illustration of Summation Reduction Source: \cite  {stack:overflow_2014}\relax }}{16}{figure.caption.19}}
\newlabel{fig:summ_red}{{\M@TitleReference {4.1}{Illustration of Summation Reduction Source: \cite  {stack:overflow_2014}\relax }}{16}{Illustration of Summation Reduction Source: \cite {stack:overflow_2014}\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Using a pipeline for back substitution}{16}{subsection.4.2.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Parallelization with CUDA}{16}{section.4.3}}
\citation{Sanders:2010:CEI:1891996}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Parallelizing with threads}{17}{subsection.4.3.1}}
\citation{parmeth}
\citation{parmeth}
\@writefile{toc}{\contentsline {subsubsection}{Complexity (Using Threads)}{19}{section*.20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Parallelization with Streaming Multiprocessors}{19}{subsection.4.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Cyclic striped scheme distributed onto processors. Source: \cite  {parmeth}\relax }}{19}{figure.caption.21}}
\newlabel{fig:row_dist}{{\M@TitleReference {4.2}{Cyclic striped scheme distributed onto processors. Source: \cite  {parmeth}\relax }}{19}{Cyclic striped scheme distributed onto processors. Source: \cite {parmeth}\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{A Small Example}{20}{section*.22}}
\newlabel{ssec:example}{{\M@TitleReference {4.3.2}{A Small Example}}{20}{A Small Example}{section*.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{Limitations}{22}{section*.23}}
\newlabel{sssec:limitations}{{\M@TitleReference {4.3.2}{Limitations}}{22}{Limitations}{section*.23}{}}
\citation{opac-b1133063}
\@writefile{toc}{\contentsline {subsubsection}{Complexity (Using SMs)}{23}{section*.24}}
\@writefile{toc}{\contentsline {subsubsection}{Parallelizing Back-substitution}{23}{section*.26}}
\citation{pipelinecomp}
\citation{pipelinecomp}
\citation{pipelinecomp}
\citation{pipelinecomp}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Reciprocal value of elements in ~\ref  {fig:impl_0and1_static_5500} and theoretical linear approximation. For calculating the elements we assumed that the limiting value $K$ should be $\sim $53.22. Each of the values were calculated according to: $r = \frac  {1}{time-K}$\relax }}{24}{figure.caption.25}}
\newlabel{fig:reciprocal}{{\M@TitleReference {4.3}{Reciprocal value of elements in ~\ref  {fig:impl_0and1_static_5500} and theoretical linear approximation. For calculating the elements we assumed that the limiting value $K$ should be $\sim $53.22. Each of the values were calculated according to: $r = \frac  {1}{time-K}$\relax }}{24}{Reciprocal value of elements in ~\ref {fig:impl_0and1_static_5500} and theoretical linear approximation. For calculating the elements we assumed that the limiting value $K$ should be $\sim $53.22. Each of the values were calculated according to: $r = \frac {1}{time-K}$\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Brief illustration of pipelined implementation of Back-Substitution Source: \cite  {pipelinecomp}\relax }}{25}{figure.caption.27}}
\newlabel{fig:pipeline}{{\M@TitleReference {4.4}{Brief illustration of pipelined implementation of Back-Substitution Source: \cite  {pipelinecomp}\relax }}{25}{Brief illustration of pipelined implementation of Back-Substitution Source: \cite {pipelinecomp}\relax }{figure.caption.27}{}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {5}Methodology For Benchmarking/Verifying The Algorithm}{29}{chapter.5}}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Hardware For Testing}{29}{section.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Methodology For Testing}{29}{section.5.2}}
\newlabel{sec:methodology_for_testing}{{\M@TitleReference {5.2}{Methodology For Testing}}{29}{Methodology For Testing}{section.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Hardware of Pluto (1)\relax }}{30}{table.caption.28}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Hardware of own system (2)\relax }}{30}{table.caption.29}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Verifying The Results}{31}{section.5.3}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {6}Results}{33}{chapter.6}}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:results}{{\M@TitleReference {6}{Results}}{33}{Results}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Sequential Performance}{33}{section.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Sequential Gaussian algorithm with Intel(R) i5-4690 CPU @ 3.50GHz\relax }}{33}{figure.caption.30}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Thread Performance of one SM}{34}{section.6.2}}
\newlabel{sec:thread_performance_of_one_sm}{{\M@TitleReference {6.2}{Thread Performance of one SM}}{34}{Thread Performance of one SM}{section.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Speedup that can be achieved when using multiple threads inside one SM (Matrixsize 900)\relax }}{34}{figure.caption.31}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Parallel Block Implementations}{34}{section.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Forward Elimination}{34}{subsection.6.3.1}}
\citation{Sanders:2010:CEI:1891996}
\citation{Kirk:2010:PMP:1841511}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Impl 0 and 1 with variable matrix size\relax }}{35}{figure.caption.32}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Comparison of Impl 0 and 1 (execution time and speedup) with a constant matrix size of 5500\relax }}{35}{figure.caption.33}}
\newlabel{fig:impl_0and1_static_5500}{{\M@TitleReference {6.4}{Comparison of Impl 0 and 1 (execution time and speedup) with a constant matrix size of 5500\relax }}{35}{Comparison of Impl 0 and 1 (execution time and speedup) with a constant matrix size of 5500\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Back Substitution}{36}{subsection.6.3.2}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Pipelined implementation VS. standard impl 1. Both use 8 blocks(SMs)\relax }}{36}{table.caption.34}}
\newlabel{my-label}{{\M@TitleReference {6.1}{Pipelined implementation VS. standard impl 1. Both use 8 blocks(SMs)\relax }}{36}{Pipelined implementation VS. standard impl 1. Both use 8 blocks(SMs)\relax }{table.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Comparison With The Maxwell Architecture}{36}{section.6.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Comparison of Impl 0 and 1 (execution time and speedup) with a constant matrix size(5500) using \textbf  {impl 1}\relax }}{37}{figure.caption.35}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Comparison between CPU and GPU}{37}{section.6.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Direct comparison: CPU vs. GPU\relax }}{38}{figure.caption.36}}
\newlabel{fig:cpu_vs_gpu_impl_1_inc_size}{{\M@TitleReference {6.6}{Direct comparison: CPU vs. GPU\relax }}{38}{Direct comparison: CPU vs. GPU\relax }{figure.caption.36}{}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {7}Conclusion}{39}{chapter.7}}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {8}Appendix: Source Code}{41}{chapter.8}}
\@writefile{loa}{\addvspace {10\p@ }}
\citation{Introduction-to-GPUs}
\citation{nvidia_kepler_2012}
\citation{toolkit}
\citation{stack:overflow_2014}
\citation{parmeth}
\citation{pipelinecomp}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{55}{section*.37}}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{57}{section*.38}}
\bibstyle{alpha}
\bibdata{bibfile}
\@writefile{toc}{\contentsline {chapter}{List of Algorithms}{59}{chapter*.39}}
\bibcite{Grcar2011163}{Grc11}
\bibcite{Kirk:2010:PMP:1841511}{KH10}
\bibcite{pipelinecomp}{Luo14}
\bibcite{toolkit}{NVI}
\bibcite{nvidia_kepler_2012}{{NVI}12}
\bibcite{Introduction-to-GPUs}{OR12}
\bibcite{parmeth}{P.06}
\bibcite{opac-b1133063}{RR10}
\bibcite{wiki:CPU_block_dia}{Sha17}
\bibcite{Sanders:2010:CEI:1891996}{SK10}
\bibcite{stack:overflow_2014}{sta14}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{61}{section*.41}}
\bibcite{tatourian}{Tat}
\bibcite{wiki:gaussian}{Wik17}
\memsetcounter{lastsheet}{76}
\memsetcounter{lastpage}{62}
